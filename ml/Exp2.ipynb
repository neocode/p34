{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 427,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "#Make the dictionary from dic_ru file\n",
    "with open('dic_ru.txt') as f:\n",
    "    dic_list = f.readlines()\n",
    "dic_list = [x.strip('\\n') for x in dic_list]\n",
    "dic = []\n",
    "for x in dic_list:\n",
    "    str_list = x.split()\n",
    "    if len(str_list) == 3:\n",
    "        #print(str_list[0], str_list[2])        \n",
    "        dic.append([str_list[0], float(str_list[2])])\n",
    "\n",
    "#print(dic)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 428,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Ordered output to the file\n",
    "with open ('dic_learn_ru.txt', 'w') as fp:    \n",
    "    for x in dic:\n",
    "        fp.write(\"%s %s %s\\n\" % (dic.index(x), x[0], x[1]))\n",
    "\n",
    "#Make the dictionary from sent_dic_ru file\n",
    "with open('sent_dic_ru.txt') as f:\n",
    "    sent = f.readlines()\n",
    "sent = [x.strip('\\n') for x in sent]                \n",
    "\n",
    "\n",
    "sent_list = []\n",
    "for x in sent:      \n",
    "    #Split into words\n",
    "    str_list = x.split()\n",
    "    \n",
    "    #List from sentenses (words in list)\n",
    "    sent_list.append(str_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 429,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pymorphy2\n",
    "\n",
    "morph = pymorphy2.MorphAnalyzer()\n",
    "def norm(word):\n",
    "    p = morph.parse(word)[0]\n",
    "    return p.normal_form, p.tag.POS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 430,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(['хороший', 'перу', 'один', 'самый', 'известный', 'участник', 'завоевание', 'гранд', 'испания', 'алкайд', 'город', 'куско', 'хороший', 'блять', 'блять', 'блять'], 1), (['экспедиция', 'продолжиться', 'видимый', 'успех'], 1), (['кандий', 'дополнение', 'получить', 'звание', 'командующий', 'артиллерия', 'который', 'сохранить', 'самый', 'свой', 'смерть'], 1), (['писарро', 'перебежать', 'альмагро', 'арестовать', 'эрнандо', 'гонсало', 'писарро'], -1), (['ценность', 'тот', 'самый', 'спрингстина'], 1), (['урих', 'являться', 'опытный', 'уважаемый', 'журналист', 'работать', 'осведомитель', 'псевдоним', 'паук'], -1), (['урих', 'использовать', 'иметься', 'информация', 'разоблачить', 'гоблин', 'начинать', 'шантажировать', 'требовать', 'большой', 'сумма', 'деньга', 'продолжить', 'покупать', 'употреблять', 'наркотик'], -1), (['расследование', 'приводить', 'барон', 'зть', 'тони', 'шокировать', 'узнать', 'зть', 'самый', 'дело', 'отец', 'мозг', 'уникальный', 'химический', 'формула', 'который', 'оставить', 'верный', 'нацист', 'готовый', 'завершить', 'свой', 'работа'], 1), (['окрашиваться', 'красный', 'цвета'], 1), (['альбом', 'являться', 'один', 'самый', 'популярный', 'творчество', 'группа'], 1)]\n"
     ]
    }
   ],
   "source": [
    "#Normalization and stop-words delete from sent_list\n",
    "sent_list_norm = []\n",
    "for sent in sent_list:\n",
    "    one_sent_list = []\n",
    "    one_sent = ()\n",
    "    if abs(float(sent[-1])) > 0.3:\n",
    "        for x in sent[:-1]:\n",
    "            x_norm = norm(x)        \n",
    "            if x_norm[1] not in ['PREP', 'PRCL', 'CONJ', 'NPRO']:\n",
    "                one_sent_list.append(x_norm[0])\n",
    "        weight = float(sent[-1])\n",
    "        if weight > 0:\n",
    "            weight_norm = 1\n",
    "        else:\n",
    "            weight_norm = -1\n",
    "        one_sent = (one_sent_list, weight_norm)\n",
    "        sent_list_norm.append(one_sent)\n",
    "print(sent_list_norm)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 431,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1, 1, 1, -1, 1, -1, -1, 1, 1, 1]\n"
     ]
    }
   ],
   "source": [
    "import collections\n",
    "\n",
    "#fp1 = open ('vect_sent.txt', 'w')\n",
    "vect_sent = []\n",
    "vect_label = []\n",
    "for x in sent_list_norm:\n",
    "    cnt = collections.Counter(x[0])\n",
    "    vect = []\n",
    "    for y in dic:       \n",
    "        if y[0] in x[0]:            \n",
    "            vect.append(cnt[y[0]])            \n",
    "        else:\n",
    "            vect.append(0)                \n",
    "    vect_sent.append(vect)\n",
    "    vect_label.append(x[1])\n",
    "#fp1.write(\"%s %s\\n\" % (vect_sent, vect_weight))\n",
    "print(vect_label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 432,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[3 0 0 ..., 0 0 0]\n",
      " [0 0 0 ..., 0 0 0]\n",
      " [0 0 0 ..., 0 0 0]\n",
      " ..., \n",
      " [0 0 0 ..., 0 0 0]\n",
      " [0 0 0 ..., 0 0 0]\n",
      " [0 0 0 ..., 0 0 0]]\n",
      "[1, 1, 1, -1, 1, -1, -1, 1, 1, 1]\n"
     ]
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "vect_sent = np.array(vect_sent)\n",
    "print(vect_sent)\n",
    "vect_weight = np.array(vect_weight)\n",
    "print(vect_label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 433,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SVC(C=1.0, cache_size=200, class_weight=None, coef0=0.0, degree=3, gamma=0.0,\n",
       "  kernel='linear', max_iter=-1, probability=False, random_state=None,\n",
       "  shrinking=True, tol=0.001, verbose=False)"
      ]
     },
     "execution_count": 433,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.svm import SVC # \"Support Vector Classifier\"\n",
    "clf = SVC(kernel='linear')\n",
    "clf.fit(vect_sent, vect_label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 434,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1])"
      ]
     },
     "execution_count": 434,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf.predict([[30, 0, 0, 0, 10, 0, 0, 0, 0, 0, 0, 0, 0, 0, 50, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 56]])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.4.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
